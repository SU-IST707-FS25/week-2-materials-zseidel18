{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8110fc71",
   "metadata": {
    "problem_id": "ex1"
   },
   "source": [
    "#### Exercise 1\n",
    "<!-- @q -->\n",
    "\n",
    "1. What kinds of EDA techniques might you use to explore the following types of data:\n",
    "    - Numeric data?  \n",
    "    - Categorical data?  \n",
    "    - The relationship between categorical and numeric data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b98cf",
   "metadata": {
    "part_id": "ex1-part1",
    "span": "ex1-part1.answer",
    "student": true
   },
   "source": [
    "For Numeric data there are many EDA techniques which include visualizing the distribution (distribution curve) and looking at summary statistics. For categorical data there are many EDA techniques which include visualizing the distribution (bar charts) in order to see all of the categories and the total number of observations within each category.   ---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af7624",
   "metadata": {
    "part_id": "ex1-part2"
   },
   "source": [
    "2. Generate some fake data (~1000 rows) with 1 categorical column (with 10 categories) and 2 numeric columns. Use the techniques you mentioned to explore the numeric, categorical, and the relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78018a6",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bdce91",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a8118",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6dab1",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5799fe",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25320be1",
   "metadata": {
    "problem_id": "2"
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "\n",
    "Generate a data set you can use with a supervised ML model.  The data should meet the following criteria:\n",
    "   - It should have 1000 rows\n",
    "   - It should have 6 columns, with one column (your \"target\" column being a boolean column), one categorical column with 5 categories, and 4 numeric columns.\n",
    "   - The numeric columns should have dramatically different scales - different means, different std. deviations.\n",
    "   - Each non-target column should have about 5% nulls.\n",
    "\n",
    "Make this data a little more interesting by calculating the target column using a noisy function of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941ebec",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "2-part1",
    "span": "2-part1.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660fce9",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "2-part1",
    "span": "2-part1.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53678de6",
   "metadata": {
    "problem_id": "ex2"
   },
   "source": [
    "#### Exercise 3\n",
    "\n",
    "Use whatever resources you need to figure out how to build an SKLearn ML pipelines. Use a pipeline to build an ML approach to predicting your target column in the preceding data with logistic regression.  I have set up the problem below so that you will write your code in a function function call that takes an SKLearn model and data frame and returns the results of a cross validation scoring routine.  \n",
    "\n",
    "I have not taught you how to do this; use the book, google, the notes, chatgpt, or whatever. This is a test of your ability to *find* information, and use this to construct a solution. Your solution should:\n",
    "\n",
    "- Use a transformer pipeline that processes your numeric and categorical features separately\n",
    "- Place everything in a pipeline with the classifier that is passed in to the function.\n",
    "- I've already implemented the call to cross_val_score - to make it work, you'll need to assign your pipeline to the `pipeline` variable.\n",
    "\n",
    "_Note: You could just feed this question to AI and get an answer, and chances are, it will be right. But if you do, you won't really learn much. So, be thoughtful in your use of AI here - you can use it to build the solution step by step, and it will explain how everything works. It's all in how you use it. So, it's your choice - go for the easy grade, or learn something._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd23a7",
   "metadata": {
    "part_id": "ex2-part1",
    "span": "ex2-part1.fill",
    "student": true
   },
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def run_classifier(df,classifier):\n",
    "    # Separate features/target\n",
    "    y = df[\"target\"].astype(int)  # logistic expects numeric; 0/1 from boolean\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "\n",
    "    #You fill in the pipeline definition.  Make sure to:\n",
    "    # - process categorical features (using an imputer and one hot encoder)\n",
    "    # - process numeric features (using an imputer and StandardScaler)\n",
    "    # - define your pipeline using `pipeline = ...`\n",
    "\n",
    "# TODO: Replace with your code (fill)\n",
    "    # --- 5-fold CV using F1\n",
    "    return cross_val_score(pipeline, X, y, scoring=\"f1\", cv=5)\n",
    "\n",
    "\n",
    "scores = run_classifier(df,LogisticRegression(random_state=42))\n",
    "print(f\"F1 (5-fold): mean={scores.mean():.3f}, std={scores.std():.3f}\")\n",
    "print(\"Fold scores:\", np.round(scores, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06eb0b",
   "metadata": {
    "part_id": "ex2-part2"
   },
   "source": [
    "Try using a `RandomForestClassifier` in the preceding pipeline. Just call `run_classifier` with a `RandomForestClassifier`, and print out the results as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65de74c",
   "metadata": {
    "part_id": "ex2-part2",
    "span": "ex2-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbb3b1",
   "metadata": {
    "part_id": "ex2-part3"
   },
   "source": [
    "Normally, `RandomForestClassifier`s are considered to be more powerful than `LogisticRegression`.  Depending on your data, this may or may not be the case. Reflect on your answers - which one does better here, and why do you think that is?  Once again, you might use AI, but you should probably also try to _understand_ the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb72f7e",
   "metadata": {
    "part_id": "ex2-part3",
    "span": "ex2-part3.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
